---
title: "Research Proposal"
author: "Eungwon Lee"

execute:
  echo: false
  
bibliography: references.bib
---

> **Abstract.**  This research investigates the relationship between monetary policy, banks' deposit, and credit  in Australia. By incorporating the deposit channel in the analysis, it is found that changes in deposits play a role in transmitting monetary policy effects on credit and real economy. The study shows that credit and real GDP respond more sensitively to monetary policy shocks when deposits are included in the model. This finding emphasizes the importance of considering the deposit channel in understanding the impact of monetary policy on credit and other macro variables in Australia.





>
> **Keywords.** SVAR, monetary policy, credit, deposit

#  The objective, question, and motivation

## Objective

The research objective is to investigate the relationship among monetary policy, banks deposit and credit growth, while considering other important macroeconomic variables in Australia, using a structural vector autoregression model. The overall question to be answered can thus be described as; How does the monetary policy and deposit growth affect the banks' credit growth in Australia?


## Motivation

The reason why the objective question is of interest is that banks' credit plays an important role in the economy as it supports investment for firms, consumption for households, and sometimes causes inflationary pressure. Thus, the effect of monetary policy on credit has been deemed to be an important concern for researchers and central bankers. A channel that explains how monetary policy works through credit is called the credit channel. In the credit channel, changes in monetary policy affect the required reserves of banks, which cause banks to change the quantity of loans they provide (e.g., @bernanke1992federal; @jimenez2014hazardous). However, the effect of changes in reserves has been estimated to be too small to exert a meaningful influence on bank lending (@woodford2010financial).

One suggestion to fill this gap is proposed by @drechsler2017deposits. In the paper, they argue that banks' credit substantially reacts to monetary policy through changes in deposits. According to their estimation, it accounts for the entire transmission of monetary policy through the bank's balance sheet. I incorporate this deposit channel in the SVAR framework to evaluate the effect of monetary policy with deposit change on banks' credit. 


#  Data and their properties

Following @berkelmans2005credit, variables are largely divided into two groups: the external and domestic sectors. For the external sector, real commodity prices (such as oil prices) and real U.S. GDP are used. The domestic sector is captured by real Australian GDP, inflation rate, banks' credit, deposit, US exchange rate, and cash rate.

At the moment, I load the related packages for the data work as follows:


```{r}
#| echo: false
#| message: false
#| warning: false
#| results: hide
rm(list=ls())
```

```{r}
#| echo: true
#| message: false
library(readrba)
library(readabs)
library(fredr)
library(tseries)
library(ggplot2)
library(cowplot)
library(dplyr)
library(zoo)
library(xts)
library(lubridate)
library(tidyr)
library(tibble)
library(lattice)
library(gridExtra)
library(FinTS)


```


The external sector is included considering Australia's status as a small open economy that heavily relies on foreign economic conditions. Commodity prices are included as they are known to capture the global business cycle that affects the domestic economy, and due to the fact that they usually ensure that the impulse responses does not show a price puzzle. The Index of Commodity Prices Australia (ICP) will be used for commodity prices. ICP is a measure of the average change in prices of Australia's major export commodities over time using price data from a basket of commodities, including minerals, agricultural products, and energy resources. The ICP is a key indicator of Australia's terms of trade. The inclusion of the U.S. GDP is also important as it has been Australia's one of the major trading partners and the largest economy that influence the world economy heavily.

For the domestic sector, real GDP is included to capture the level of domestic economic activity, while the inflation rate is included as the Reserve Bank of Australia (RBA) has adopted an inflation target since 1990, which strongly affects monetary policy. Banks' credit and deposit are key variables in the model as they form contemporaneous relationship with monetary policy. Finally, the cash rate is the primary tool of monetary policy for the RBA, and it is therefore an essential variable to include in the model. 

Quarterly data between Q1 1990 and Q2 2019 was acquired from the Reserve Bank of Australia (RBA) and the Australian Bureau of Statistics (ABS) using the "readrba" and "readabs" packages in R. The data were mostly transformed into logarithmic form, except for exchange rate and cash rate, allowing the coefficients to be interpreted as elasticities. The exchange rate is presented AUD/USD, while the cash rate is presented in percentage.

Unfortunately, I cannot use data prior to Q1 1990 as RBA adopted the cash rate as its primary policy tool in the early 1990s, replacing the "interest rate on 90-day bills" as the target for monetary policy. Additionally, I cannot use data after Q2 2019 due to a break in the credit data at that time.

```{r}
#| echo: false
#| message: false
#| warning: false
#| results: hide

# test

# I would suggest that you merged all the data into one table, such that you can call them easier. Doing this would also enable you to do loops over the variables. I have attached my own merge, which you can use if interested. You could then do ADF, ACF and plot using a loop over the variables in the table! I have included my own code of ADF if interested (I know that the code could be more efficiently written). 

#Merging the series into vector Y
#Y = na.omit(merge(tindp, tcpi, texpec, tlend, thp, tfci))
#colnames(Y)<- c("indu", "cpi", "exp", "lend","hp","fci")

# Code for ADF
#max_lag = 12
#adf_ <- list()
#for (i in 1:6) {
#  adf_result = adf.test(Y[,i], k = max_lag)
#  adf_[[i]] <- adf_result
#}
#head(adf_)

# View the ADF test results
#summary(adf_result)

#adf_table <- data.frame(Test_Statistic = numeric(length(adf_)), 
#                        p_value = numeric(length(adf_)), 
#                        Lags_Used = numeric(length(adf_)))

# Fill in the data frame with the test results
#for (i in 1:length(adf_)) {
#  adf_table[i, "Test_Statistic"] = round(adf_[[i]]$statistic,3)
#  adf_table[i, "p_value"] = round(adf_[[i]]$p.value,3)
#  adf_table[i, "Lags_Used"] = round(adf_[[i]]$parameter,3)
#}
```



```{r, warning=FALSE, message=FALSE}
#| echo: false
#| message: false
#| warning: false
#| results: hide

# load data from RBA and FRB
temp_ex_comp          <- readrba::read_rba(series_id = "GRCPAIAD")
                         fredr_set_key("7afc2e18e3cf3585055851ad2f310f53")
temp_ex_usrealgdp     <- fredr(series_id = "GDPC1")

temp_dm_realgdp       <- readrba::read_rba(series_id = "GGDPCVGDP")
temp_dm_price         <- readrba::read_rba(series_id = "GCPIAG")
temp_dm_credit        <- readrba::read_rba(series_id = "DLCACN")
   temp_M3            <- readrba::read_rba(series_id = "DMAM3N")
   temp_currency      <- readrba::read_rba(series_id = "DMACN")
   value              <- temp_M3$value - temp_currency$value
temp_dm_deposit       <- cbind(temp_M3[,1], value, temp_M3[,4])
temp_dm_us_ex_rate    <- readrba::read_rba(series_id = "FXRUSD")
temp_dm_cashrate      <- read_cashrate(type = c("target"))

# change data to quarterly
ex_comp          <- to.quarterly(xts(temp_ex_comp$value, temp_ex_comp$date), OHLC = FALSE)
ex_usrealgdp     <- to.quarterly(xts(temp_ex_usrealgdp$value, temp_ex_usrealgdp$date), OHLC = FALSE)
dm_realgdp       <- to.quarterly(xts(temp_dm_realgdp$value, temp_dm_realgdp$date), OHLC = FALSE)
dm_price         <- to.quarterly(xts(temp_dm_price$value, temp_dm_price$date), OHLC = FALSE)
dm_credit        <- to.quarterly(xts(temp_dm_credit$value, temp_dm_credit$date), OHLC = FALSE)
dm_deposit       <- to.quarterly(xts(temp_dm_deposit$value, temp_dm_deposit$date), OHLC = FALSE)
dm_us_ex_rate    <- to.quarterly(xts(temp_dm_us_ex_rate$value, temp_dm_us_ex_rate$date), OHLC = FALSE)
dm_cashrate      <- to.quarterly(xts(temp_dm_cashrate$value, temp_dm_cashrate$date), OHLC = FALSE) 

# unify date so that I can merge with other data
index(ex_usrealgdp) <- seq(as.Date("1947-03-01"), by = "3 months", length.out = nrow(ex_usrealgdp))
index(dm_realgdp)   <- seq(as.Date("1959-09-01"), by = "3 months", length.out = nrow(dm_realgdp))
index(dm_price)     <- as.yearqtr(index(dm_price))
index(dm_realgdp)   <- as.yearqtr(index(dm_realgdp))
index(ex_usrealgdp) <- as.yearqtr(index(ex_usrealgdp))

# merge original data
merged_data  <- na.omit(merge(ex_comp, ex_usrealgdp, dm_realgdp, dm_price, dm_credit, dm_deposit, dm_us_ex_rate, dm_cashrate))
                           
# transform original data into log
log_merged_data <- log(merged_data)

# merge original and log transformed data for estimation
# dm_us_ex_rate, dm_cashrate are original, others are log transformed.
y           = cbind(log_merged_data[,1],
                    log_merged_data[,2],
                    log_merged_data[,3],
                    log_merged_data[,4],
                        merged_data[,8],
                    log_merged_data[,6],
                    log_merged_data[,5],
                        merged_data[,7]
                    )


```






Below is how data look like. As we see below, stock and flow variables mostly have upward trend and it disappears when I take difference. Some variables such as GDP and deposit exhibit spark around 2020 as below.

###### Figure 1. Time series of log variables from 1990 Q1 to 2019 Q2 except USD exchange rate and cash rate is not {style="text-align: center;"}


```{r, warning=FALSE, message=FALSE}

#| echo: false
#| message: false
#| warning: false
#| results: hide

# This code is from Thomas Kronholm Moeller.

pl_ex_comp = ggplot(data = log_merged_data[,1], aes(x = index(log_merged_data[,1]), y = log_merged_data[,1])) +
  geom_line(color = "black") +
  labs(title = "Commodity Price", x = "Year", y = "Ln Commodity Price") +
  scale_x_continuous(limits = c(1990, 2019))+
  theme_minimal()

pl_ex_usrealgdp = ggplot(data = log_merged_data[,2], aes(x = index(log_merged_data[,2]), y = log_merged_data[,2])) +
  geom_line(color = "black") +
  labs(title = "US Real GDP", x = "Year", y = "Ln US Real GDP") +
  scale_x_continuous(limits = c(1990, 2019))+
  theme_minimal()

pl_dm_realgdp = ggplot(data = log_merged_data[,3], aes(x = index(log_merged_data[,3]), y = log_merged_data[,3])) +
  geom_line(color = "black") +
  labs(title = "Australia Real GDP", x = "Year", y = "Ln Au Real GDP") +
  scale_x_continuous(limits = c(1990, 2019))+
  theme_minimal()

pl_dm_price = ggplot(data = log_merged_data[,4], aes(x = index(log_merged_data[,4]), y = log_merged_data[,4])) +
  geom_line(color = "black") +
  labs(title = "Consumer Price Index", x = "Year", y = "Ln Index") +
  scale_x_continuous(limits = c(1990, 2019))+
  theme_minimal()

pl_dm_credit = ggplot(data = log_merged_data[,5], aes(x = index(log_merged_data[,5]), y = log_merged_data[,5])) +
  geom_line(color = "black") +
  labs(title = "Bank Total Credit", x = "Year", y = "Ln Credit") +
  scale_x_continuous(limits = c(1990, 2019))+
  theme_minimal()

pl_dm_deposit = ggplot(data = log_merged_data[,6], aes(x = index(log_merged_data[,6]), y = log_merged_data[,6])) +
  geom_line(color = "black") +
  labs(title = "Bank Deposit", x = "Year", y = "Ln Deposit") +
  scale_x_continuous(limits = c(1990, 2019))+
  theme_minimal()

pl_dm_us_ex_rate = ggplot(data = merged_data[,7], aes(x = index(merged_data[,7]), y = merged_data[,7])) +
  geom_line(color = "black") +
  labs(title = "US Exchange Rate", x = "Year", y = "AUD/USD") +
  scale_x_continuous(limits = c(1990, 2019))+
  theme_minimal()

pl_dm_cashrate = ggplot(data = merged_data[,8], aes(x = index(merged_data[,8]), y = merged_data[,8])) +
  geom_line(color = "black") +
  labs(title = "Cash Rate", x = "Year", y = "Cash Rate (%)") +
  scale_x_continuous(limits = c(1990, 2019))+
  theme_minimal()


grid.arrange(pl_ex_comp, pl_ex_usrealgdp, pl_dm_realgdp, pl_dm_price, pl_dm_credit, pl_dm_deposit, pl_dm_us_ex_rate, pl_dm_cashrate, nrow = 3, ncol = 3)

```

# 

Once we take the first difference between quarters, we observe that the trend disappears from most of the data. However, we still observe that first differenced banks credit and deposit seems to exhibit some trend. At the same time, we see that variances are still quite different across time in most of the variables.



###### Figure 2. Time series of log differenced variables from 1990 Q1 to 2019 Q2 {style="text-align: center;"}


```{r, warning=FALSE, message=FALSE}
#| echo: false
#| message: false
#| warning: false
#| results: hide

# This code is from Thomas Kronholm Moeller.

# difference quarter on quarter
dff_merged_data <- na.omit(merged_data - stats::lag(merged_data))
dff_log_merged_data <- na.omit(log_merged_data - stats::lag(log_merged_data))


dff_pl_ex_comp = ggplot(data = dff_log_merged_data[,1], aes(x = index(dff_log_merged_data[,1]), y = dff_log_merged_data[,1])) +
  geom_line(color = "black") +
  labs(title = "Commodity Price", x = "Year", y = "Ln Difference") +
  scale_x_continuous(limits = c(1990, 2019))+
  theme_minimal()

dff_pl_ex_usrealgdp = ggplot(data = dff_log_merged_data[,2], aes(x = index(dff_log_merged_data[,2]), y = dff_log_merged_data[,2])) +
  geom_line(color = "black") +
  labs(title = "US Real GDP", x = "Year", y = "Ln Difference") +
  scale_x_continuous(limits = c(1990, 2019))+
  theme_minimal()

dff_pl_dm_realgdp = ggplot(data = dff_log_merged_data[,3], aes(x = index(dff_log_merged_data[,3]), y = dff_log_merged_data[,3])) +
  geom_line(color = "black") +
  labs(title = "Australia Real GDP", x = "Year", y = "Ln Difference") +
  scale_x_continuous(limits = c(1990, 2019))+
  theme_minimal()

dff_pl_dm_price = ggplot(data = dff_log_merged_data[,4], aes(x = index(dff_log_merged_data[,4]), y = dff_log_merged_data[,4])) +
  geom_line(color = "black") +
  labs(title = "Consumer Price Index", x = "Year", y = "Ln Difference") +
  scale_x_continuous(limits = c(1990, 2019))+
  theme_minimal()

dff_pl_dm_credit = ggplot(data = dff_log_merged_data[,5], aes(x = index(dff_log_merged_data[,5]), y = dff_log_merged_data[,5])) +
  geom_line(color = "black") +
  labs(title = "Bank Total Credit", x = "Year", y = "Ln Difference") +
  scale_x_continuous(limits = c(1990, 2019))+
  theme_minimal()

dff_pl_dm_deposit = ggplot(data = dff_log_merged_data[,6], aes(x = index(dff_log_merged_data[,6]), y = dff_log_merged_data[,6])) +
  geom_line(color = "black") +
  labs(title = "Bank Deposit", x = "Year", y = "Ln Difference") +
  scale_x_continuous(limits = c(1990, 2019))+
  theme_minimal()

dff_pl_dm_us_ex_rate = ggplot(data = dff_merged_data[,7], aes(x = index(dff_merged_data[,7]), y = dff_merged_data[,7])) +
  geom_line(color = "black") +
  labs(title = "US Exchange Rate", x = "Year", y = "Difference") +
  scale_x_continuous(limits = c(1990, 2019))+
  theme_minimal()

dff_pl_dm_cashrate = ggplot(data = dff_merged_data[,8], aes(x = index(dff_merged_data[,8]), y = dff_merged_data[,8])) +
  geom_line(color = "black") +
  labs(title = "Cash Rate", x = "Year", y = "Difference (%p)") +
  scale_x_continuous(limits = c(1990, 2019))+
  theme_minimal()

grid.arrange(dff_pl_ex_comp, dff_pl_ex_usrealgdp, dff_pl_dm_realgdp, dff_pl_dm_price, dff_pl_dm_credit, dff_pl_dm_deposit, dff_pl_dm_us_ex_rate, dff_pl_dm_cashrate, nrow = 3, ncol = 3)

```
#

Autocorrelation Function (ACF) plots show the correlation between a time series and its lagged values. Stock variables such as credit and deposit exhibit the most strong correlation in time series while exchange rate and cash rate show relatively weak correlation between periods.

###### Figure 3. Autocorrelation function (ACF) plots (all log term except exchange rate and cash rate) {style="text-align: center;"}


```{r ACF plots, echo = FALSE}

# This code is from Ray Gomez.

par(mfrow=c(2,4))
a_ex_comp = acf(log_merged_data[,1], main = "ACF, Commodity Pice", ylab = "Autocorrelation", type = "correlation")
a_ex_usrealgdp = acf(log_merged_data[,2], main = "ACF, US Real GDP", ylab = "Autocorrelation", type = "correlation")
a_dm_realgdp = acf(log_merged_data[,3], main = "ACF, AU Real GDP", ylab = "Autocorrelation", type = "correlation")
a_dm_price = acf(log_merged_data[,4],  main = "ACF, CPI", ylab = "Autocorrelation", type = "correlation")
a_dm_credit = acf(log_merged_data[,5], main = "ACF, Total Credit", ylab = "Autocorrelation", type = "correlation")
a_dm_deposit = acf(log_merged_data[,6], main = "ACF, Total Deposit", ylab = "Autocorrelation", type = "correlation")
a_dm_us_ex_rate = acf(merged_data[,7],  main = "ACF, Exchange Rate", ylab = "Autocorrelation", type = "correlation")
a_dm_cashrate = acf(merged_data[,8],  main = "ACF, Cash Rate", ylab = "Autocorrelation", type = "correlation")
```
#
The Partial Autocorrelation Function (PACF) is the correlation between a time series and a lagged version of itself, controlling for the values of the intermediate lags. The PACF plot shows the partial correlation coefficients between the time series and its lags. These coefficients represent the correlation between the time series and the lagged values of itself, with the effect of the intermediate lags removed. We see that for most of the variables, first lag is an important predictor of the current value of the time series. 

###### Figure 4. Partial Autocorrelation function (PACF) plots {style="text-align: center;"}

```{r PACF plots, echo = FALSE}

# This code is from Ray Gomez

par(mfrow=c(2,4))
pa_ex_comp = pacf(log_merged_data[,1], main = "PACF, Commodity Pice")
pa_ex_usrealgdp = pacf(log_merged_data[,2], main = "PACF, US Real GDP")
pa_dm_realgdp = pacf(log_merged_data[,3], main = "PACF, AU Real GDP")
pa_dm_price = pacf(log_merged_data[,4],  main = "PACF, CPI")
pa_dm_credit = pacf(log_merged_data[,5], main = "PACF, Total Credit")
pa_dm_deposit = pacf(log_merged_data[,6], main = "PACF, Total Deposit")
pa_dm_us_ex_rate = pacf(merged_data[,7],  main = "PACF, Exchange Rate")
pa_dm_cashrate = pacf(merged_data[,8],  main = "PACF, Cash Rate")
```




## Integration order verification

I conduct Augmented Dickey-Fuller test for log transformed variables and original cash rate and exchange rate using the "adf()" function to examines the presence of a unit root in the time series. The results of the test are displayed in the table below. Across all variables except exchange rate, I cannot not reject the null hypothesis of unit root. It indicates that the time series is non-stationary and requires differencing to achieve stationarity.


```{r ADF test1}
#| echo: false
#| message: false
#| warning: false
#| results: hide

# This code is from Thomas Kronholm Moeller.
#ADF test

adf_ <- list()
for (i in 1:8) {
  adf_result = adf.test(y[,i], k = 4)
  adf_[[i]] <- adf_result
}

head(adf_)

# View the ADF test results
summary(adf_result)

adf_table <- data.frame(Test_Statistic = numeric(length(adf_)), 
                        p_value = numeric(length(adf_)), 
                        Lags_Used = numeric(length(adf_)))

# Fill in the data frame with the test results
for (i in 1:length(adf_)) {
  adf_table[i, "Test_Statistic"] = round(adf_[[i]]$statistic,3)
  adf_table[i, "p_value"] = round(adf_[[i]]$p.value,3)
  adf_table[i, "Lags_Used"] = round(adf_[[i]]$parameter,3)
}
```

###### Table 1. Augmented Dickey-Fuller test for log transformed variables except ex_rate and cash rate {style="text-align: center;"}
```{r ADF test1 print}
#| echo: false
#| message: false
#| warning: false


# Print the data frame
rownames(adf_table)<- c("Commodity price", "US real GDP", "AU Real GDP", "CPI","Cash rate","Banks' deposit", "Banks' credit", "USD exchange rate")
colnames(adf_table)<- c("Test statistic", "P-value", "Lags")
print(adf_table)


```

#

Then I conduct Augmented Dickey-Fuller test for first differenced log transformed variables and original cash rate and exchange rate using the "adf()" function to examines the presence of a unit root in the differenced time series. The results of the test are displayed in the table below. As we can expect, most of variables except banks' deposit and credit, P-values of the tests are below 5% or 1%, implying the rejection of null hypothesis of unit root. 


```{r ADF test2}
#| echo: false
#| message: false
#| warning: false
#| results: hide


# This code is from Thomas Kronholm Moeller.

# compute dfferenced variables
dff_y           = cbind(dff_log_merged_data[,1],
                         dff_log_merged_data[,2],
                         dff_log_merged_data[,3],
                         dff_log_merged_data[,4],
                             dff_merged_data[,8],
                         dff_log_merged_data[,6],
                         dff_log_merged_data[,5],
                             dff_merged_data[,7]
                  
                    
)

# ADF test
dff_adf_ <- list()
for (i in 1:8) {
  dff_adf_result = adf.test(dff_y[,i], k = 4)
  dff_adf_[[i]] <- dff_adf_result
}

head(dff_adf_)

# View the ADF test results
summary(dff_adf_result)

dff_adf_table <- data.frame(Test_Statistic = numeric(length(dff_adf_)), 
                        p_value = numeric(length(dff_adf_)), 
                        Lags_Used = numeric(length(dff_adf_)))

# Fill in the data frame with the test results
for (i in 1:length(dff_adf_)) {
  dff_adf_table[i, "Test_Statistic"] = round(dff_adf_[[i]]$statistic,3)
  dff_adf_table[i, "p_value"] = round(dff_adf_[[i]]$p.value,3)
  dff_adf_table[i, "Lags_Used"] = round(dff_adf_[[i]]$parameter,3)
}

```

###### Table 2. Augmented Dickey-Fuller test for quarter on quarter differenced variables {style="text-align: center;"}
```{r ADF test2 print}
#| echo: false
#| message: false
#| warning: false


# Print the data frame
rownames(dff_adf_table)<- c("Commodity price", "US real GDP", "AU Real GDP", "CPI","Cash rate","Banks' deposit", "Banks' credit", "USD exchange rate")
colnames(dff_adf_table)<- c("Test statistic", "P-value", "Lags")
print(dff_adf_table)


```

This raises the issue of the appropriate estimation methodology. Some papers (i.g. Berkelmans, 2005) estimate SVAR in levels even when the variables are I(1) while others (Siami-Namini, 2016) use first differences in their model.



# The model and hypothesis

## The model

The structural VAR model with $4$ lags is given by

$$
\begin{align}
  B_0y_t &= b_0 + B_1 y_{t-1} + \dots + B_4 y_{t-4} + u_t \\
  u_{t}| Y_{t-1} &\sim {iid} ( 0_N, I_N)
\end{align}
$$
Where $B_0$ is a matrix of contemporaneous relationships, $y_t$ is a vector of endogenous variables, $y_{t-1}$, $\dots$, $y_{t-1}$ are vectors of lags, and $u_t$ is a vector of independent structural shocks.

$y_t$ contains eight variables: commodity prices ($com_t$), the U.S. real GDP ($usgdp_t$), domestic real GDP ($gdp_t$), inflation rate($\pi_t$),  cash rate ($i_t$), banks' deposit($d_t$), banks' credit($c_t$), and USD exchange rate ($ex_t$).

Premultiplying $B_0^{-1}$ to the structural VAR model gives us the reduced form representation as follows:

$$
\begin{align}
  y_t &= \mu_0 + A_1 y_{t-1} + \dots + A_4 y_{t-4} + \epsilon_t \\
  \epsilon_{t}| Y_{t-1} &\sim {iid} ( 0_N, \Sigma)
\end{align}
$$
where $A_i=B_0^{-1}B_i$, $\epsilon_t=B_0^{-1}u_t$, and $\Sigma=$$B_0^{-1}B_0^{-1 \prime}$

Using the reduced form equations, we can estimate $\Sigma$. However $\Sigma$ has $8(8+1)/2=36$ unique elements, which is the number of equations, yet we have $8^2=64$ unknowns in $B_0$. Hence I impose exclusion restrictions on $B_0$ to identify the system.


# Hypothesis
I want to estimate how monetary shocks affect credit while controlling for deposits. I expect that credit will be less responsive to monetary policy when deposits are included as an endogenous variable. This expectation is consistent with the deposit channel of monetary policy, where banks' credit is heavily influenced by changes in deposits in response to monetary policy.


# Identiying assumptions: case 1

In this case, I apply a lower triangular matrix to $B_0$ matrix.

Assumptions for $B_0$ matrix is as follows:

- Since Australian economy is a small open economy, I assume that the domestic variables have no effect on external variables while shocks from the external sector have simultaneous effect on the domestic economy.
- GDP is affected from the external sector but not affected by other domestic variables contemporaneously 
- Inflation is affected from the external sector and GDP but not affected by other domestic variables contemporaneously.
- Cash rate is affected from the external sector, GDP and inflation but not affected by other domestic variables contemporaneously.
- Deposit is affected from the external sector, GDP, inflation, and cash rate but not affected by other domestic variables contemporaneously. I assume that profit maximization motive makes banks to adjust the deposit rate at the same period that RBA adjusts the cash rate. And deposit volume changes accordingly.
- Credit is affected from the external sector, GDP, inflation, cash rate, and deposit but not affected by other domestic variables contemporaneously. Since the deposit is the most stable and major funding source for banks, I assume that banks reduces credit outstanding in response to deposit change.
- The exchange rate is affected from all variables contemporaneously.


Following equation summarizes the contemporaneous relationships among the variables:


$$
B_0y_t =
\begin{bmatrix}
a_{11} & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
a_{21} & a_{22} & 0 & 0 & 0 & 0 & 0 & 0 \\
a_{31} & a_{32} & a_{33} & 0 & 0 & 0 & 0 & 0 \\
a_{41} & a_{42} & a_{43} & a_{44} & 0 & 0 & 0 & 0 \\
a_{51} & a_{52} & a_{53} & a_{54} & a_{55} & 0 & 0 & 0 \\
a_{61} & a_{62} & a_{63} & a_{64} & a_{65} & a_{66} & 0 & 0 \\
a_{71} & a_{72} & a_{73} & a_{74} & a_{75} & a_{76} & a_{77} & 0 \\
a_{81} & a_{82} & a_{83} & a_{84} & a_{85} & a_{86} & a_{87} & a_{88} \\
\end{bmatrix}
\begin{bmatrix}
com_t \\
usgdp_t \\
gdp_t \\
\pi_t \\
i_t \\
deposit_t \\
credit_t \\
ex_t \\
\end{bmatrix}
$$


Note that this assumption and thus order of the variables in $y_t$ is subject to change over the course of the research upon any better identifying assumptions. One problem that arises from using quarterly data instead of monthly is difficulty of setting identifying assumptions. When it is monthly data, we can utilize the assumption of informational delay. When deciding on monetary policy in the Australian economy, RBA takes into consideration a range of variables including, but are not limited to, CPI and GDP. However, due to informational delay, CPI, GDP, and other relevant variables may not be immediately available to the monetary authorities. This allows us to claim no contemporaneous relation between policy rate and some variables. This is difficult to argue in quarterly data since a quarter may be enough time to have contemporaneous relation between policy rate and some other variables.





```{r results for case 1}
#| echo: false
#| message: false
#| warning: false
#| results: hide

# This code is from ECOM90007 L12 codes provided by Tomasz Woźniak.

library(mvtnorm)
library(plot3D)
library(HDInterval)
set.seed(123456)

# Define colors
mcxs1  = "#05386B"
mcxs2  = "#379683"
mcxs3  = "#5CDB95"
mcxs4  = "#8EE4AF"
mcxs5  = "#EDF5E1"
purple = "#b02442"

mcxs1.rgb   = col2rgb(mcxs1)
mcxs1.shade1= rgb(mcxs1.rgb[1],mcxs1.rgb[2],mcxs1.rgb[3], alpha=120, maxColorValue=255)
mcxs2.rgb   = col2rgb(mcxs2)
mcxs2.shade1= rgb(mcxs2.rgb[1],mcxs2.rgb[2],mcxs2.rgb[3], alpha=120, maxColorValue=255)

# setup
############################################################
N       = 8
p       = 4
S       = 50000
#h      = 8
h       = 10

# create Y and X
############################################################
y       = ts(y)
Y       = ts(y[5:118,], start=c(1991,1), frequency=4)
X       = matrix(1,nrow(Y),1)
for (i in 1:p){
  X     = cbind(X,y[5:118-i,])
}


t0          = proc.time() # read processor time

# MLE
############################################################
A.hat       = solve(t(X)%*%X)%*%t(X)%*%Y
Sigma.hat   = t(Y-X%*%A.hat)%*%(Y-X%*%A.hat)/nrow(Y)
# round(A.hat,3)
# round(Sigma.hat,3)
# round(cov2cor(Sigma.hat),3)

```

## The prior distibution

The prior parameters are set as follows: $\kappa_1$, which is the overall shrinkage parameter to control the dispersion around the prior mean, is set to 1. $\kappa_2$, the overall shrinkage for the constant term, is set to 100. $\kappa_3$ is set to 1.

```{r}
#| echo: true
#| message: false

# Parameters for prior distribution 
############################################################
kappa.1        = 1^2
kappa.2        = 100
kappa.3        = 1
A.prior        = matrix(0,nrow(A.hat),ncol(A.hat))
A.prior[2:9,]  = kappa.3*diag(N)
V.prior        = diag(c(kappa.2,kappa.1*((1:p)^(-2))%x%rep(1,N)))
S.prior        = diag(diag(Sigma.hat))
nu.prior       = N+1
```

## The posterior distibution

Using the likelihood and the prior distribution I obtain the posterior as follows:
```{r results for case 1_contd}
#| echo: true
#| message: false

# normal-inverse Wishard posterior parameters
############################################################
V.bar.inv   = t(X)%*%X + diag(1/diag(V.prior))
V.bar       = solve(V.bar.inv)
A.bar       = V.bar%*%(t(X)%*%Y + diag(1/diag(V.prior))%*%A.prior)
nu.bar      = nrow(Y) + nu.prior
S.bar       = S.prior + t(Y)%*%Y + t(A.prior)%*%diag(1/diag(V.prior))%*%A.prior - t(A.bar)%*%V.bar.inv%*%A.bar
S.bar.inv   = solve(S.bar)

# posterior draws 
############################################################
Sigma.posterior   = rWishart(S, df=nu.bar, Sigma=S.bar.inv)
Sigma.posterior   = apply(Sigma.posterior,3,solve)
Sigma.posterior   = array(Sigma.posterior,c(N,N,S))
A.posterior       = array(rnorm(prod(c(dim(A.bar),S))),c(dim(A.bar),S))
B.posterior       = array(NA,c(N,N,S))
L                 = t(chol(V.bar))
for (s in 1:S){
  cholSigma.s     = chol(Sigma.posterior[,,s])
  B.posterior[,,s]= t(cholSigma.s)
  A.posterior[,,s]= A.bar + L%*%A.posterior[,,s]%*%cholSigma.s
}
```


## Empirical Investigation for baseline model (case 1)

As we see the Impulse Response Functions (IRFs) below, upon a cash rate shock, Australian real GDP decreases for more than a year and the impact statistically becomes zero in a longer term, deposit increases for nearly two years and then the impact becomes statistically zero in a longer term, price increases and then the effect gradually becomes zero, credit, which is the variable of my interest, increases in the short term for about a year and then decreases and the effect becomes statistically zero, and exchange rate increases shortly and then becomes statistically indistinguishable from zero.

```{r results for case 1_contd2}
#| echo: false
#| message: false
#| warning: false
#| results: hide

# Impulse response functions
# Forecast Error Variance Decomposition
############################################################
IRF.posterior     = array(NA,c(N,N,h+1,S))
IRF.inf.posterior = array(NA,c(N,N,S))
FEVD.posterior    = array(NA,c(N,N,h+1,S))
J                 = cbind(diag(N),matrix(0,N,N*(p-1)))
for (s in 1:S){
  A.bold          = rbind(t(A.posterior[2:(1+N*p),,s]),cbind(diag(N*(p-1)),matrix(0,N*(p-1),N)))
  IRF.inf.posterior[,,s]          = J %*% solve(diag(N*p)-A.bold) %*% t(J) %*% B.posterior[,,s]
  A.bold.power    = A.bold
  for (i in 1:(h+1)){
    if (i==1){
      IRF.posterior[,,i,s]        = B.posterior[,,s]
    } else {
      IRF.posterior[,,i,s]        = J %*% A.bold.power %*% t(J) %*% IRF.posterior[,,i-1,s]
      A.bold.power                = A.bold.power %*% A.bold
    }
    for (n in 1:N){
      for (nn in 1:N){
        FEVD.posterior[n,nn,i,s]  = sum(IRF.posterior[n,nn,1:i,s]^2)
      }
    }
    FEVD.posterior[,,i,s]         = diag(1/apply(FEVD.posterior[,,i,s],1,sum))%*%FEVD.posterior[,,i,s]
  }
}
FEVD.posterior    = 100*FEVD.posterior

t1          = proc.time()
(t1-t0)[3]/60 # Time of computations in minutes

# save(IRF.posterior,IRF.inf.posterior, FEVD.posterior, file="irf-fevd-k002.RData")
save(IRF.posterior,IRF.inf.posterior, FEVD.posterior, file="irf-fevd-k1.RData")


# Plots of responses to domestic monetary policy shock
############################################################
load("irf-fevd-k1.RData")
IRFs.k1           = apply(IRF.posterior[3:8,5,,],1:2,mean)
IRFs.inf.k1       = apply(IRF.inf.posterior[3:8,5,],1,mean)
#rownames(IRFs.k1) = colnames(Y)[3:8]
rownames(IRFs.k1) = c('GDP','CPI','Cash Rate','Deposits','Bank Credit','AUD/USD ER')

IRFs.k1.hdi    = apply(IRF.posterior[3:8,5,,],1:2,hdi, credMass=0.68)
hh             = 1:11
```





###### Figure 5. IRF to cash rate shock for $\kappa_1$ = 1 plots {style="text-align: center;"}

```{r irf-au-mps plots, echo = FALSE}

# irf-au-mps plots

# par(mfrow=c(3,2), mar=c(4,4.5,2,2),cex.axis=1.5, cex.lab=1.5)
# for (n in 1:6){
#   ylims     = range(IRFs.k1[n,hh],IRFs.k1.hdi[,n,hh])
#   plot(hh,IRFs.k1[n,hh], type="l", ylim=ylims, axes=FALSE, xlab="", ylab=rownames(IRFs.k1)[n])
#   if (n==5 | n==6){
#     axis(1,c(1,2,6,11),c("","1 quarter","5 quarter","10 quarter"))
#   } else {
#     axis(1,c(1,2,6,11),c("","","",""))
#   }
#   axis(2,c(ylims[1],0,ylims[2]),round(c(ylims[1],0,ylims[2]),3))
#   polygon(c(hh,(h+1):1), c(IRFs.k1.hdi[1,n,hh],IRFs.k1.hdi[2,n,(h+1):1]), col=mcxs1.shade1,border=mcxs1.shade1)
#   abline(h=0)
#   lines(hh, IRFs.k1[n,hh],lwd=2,col=mcxs1)
#   
# }

plot_irfs = function(irfs, irfs.hdi, hhs, x.locs, x.labs){
  par(mfrow=c(3,2), mar=c(4,4.5,2,2),cex.axis=1.5, cex.lab=1.5)
  for (n in 1:nrow(irfs)){
    ylims     = range(irfs[n,hhs],irfs.hdi[,n,hhs])
    plot(hhs,irfs[n,hhs], type="l", ylim=ylims, axes=FALSE, xlab="", ylab=rownames(irfs)[n])
    if (n==(nrow(irfs)-1) | n==nrow(irfs)){
      axis(1,x.locs,x.labs)
    } else {
      axis(1,x.locs,c("","","",""))
    }
    axis(2,c(ylims[1],0,ylims[2]),round(c(ylims[1],0,ylims[2]),3))
    polygon(c(hhs,(h+1):1), c(irfs.hdi[1,n,hhs],irfs.hdi[2,n,(h+1):1]), col=mcxs1.shade1,border=mcxs1.shade1)
    abline(h=0)
    lines(hhs, irfs[n,hhs],lwd=2,col=mcxs1)
  }
}

plot_irfs(IRFs.k1, IRFs.k1.hdi, hh, c(1,2,6,11), c('','1 quarter','5 quarter','10 quarter'))

```


#
The contribution of the shocks to the mean square forecast error (MSFE) of the credit for 10 quarters ahead is given below. Specifically, it provides a sense of the relative importance of shocks in explaining the forecast variability of credit quantifying the percentage of the forecast error variance of credit that can be attributed to its own shocks and the shocks of other variables such as cash rate. Initially, its own shock contribute the most of the variance. However, as it proceeds, the role of its own shock shrinks considerably while other variables, especially cash rate (mps in the figure) explains much more of the variance as time goes by.

###### Figure 6. FEVD of banks' credit plots {style="text-align: center;"}


```{r fevd-credit plots, echo = FALSE}
# Plots of FEVD of Australian banks credit
############################################################
load("irf-fevd-k1.RData")
hh            = 1:(h+1)
fevd.au.credit= apply(FEVD.posterior[7,,,],1:2,mean)
fevd.au.credit= rbind(rep(0,h+1),apply(fevd.au.credit,2,cumsum))

colors = c("deepskyblue1","deepskyblue2","maroon1","maroon","maroon2","magenta","maroon3","maroon4")


par(mar=rep(4,4),cex.axis=1, cex.lab=0.8)
plot(hh,fevd.au.credit[1,], type="n", ylim=c(0,100), axes=FALSE, xlab="", ylab="")
axis(1,hh,c("","1 quarter","","","","5 quarter","","","","","10 quarter"))
axis(2,c(0,50,100),c("","FEVD[au.credit]",""))
for (n in 1:N){
  polygon(c(hh,(h+1):1), c(fevd.au.credit[n,hh],fevd.au.credit[n+1,(h+1):1]), col=colors[n],border=colors[n])
}
axis(4, (0.5*(fevd.au.credit[1:8,7]+fevd.au.credit[2:9,7]))[c(5,7)], c("mps","crd"))

```






# Identiying assumptions: case 2(Long-run restriction)

In case 2, I additionally apply a long-run restriction to the baseline model (case 1 model). The restriction that I additionally impose is that monetary policy has no effect on the Australian real GDP in the long run. Since the algorithm (Algorithm 1 in lecture 13) I use works only for exactly identified models, the restrictions of interest to be imposed on the system must exactly identify the model. Hence, to make a room for a long-run restriction, I allow monetary policy to have an effect on the Australian real GDP contemporaneously and then I impose a restriction that the monetary policy has no effect on the Australian real GDP in the long run.

Following equation summarizes the restrictions I impose for IRFs on horizons 0 and $\infty$:


$$
\begin{align*}
\Theta_0 = B = B_0^{-1} &=
\begin{bmatrix}
* & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
* & * & 0 & 0 & 0 & 0 & 0 & 0 \\
* & * & * & 0 & * & 0 & 0 & 0 \\
* & * & * & * & 0 & 0 & 0 & 0 \\
* & * & * & * & * & 0 & 0 & 0 \\
* & * & * & * & * & * & 0 & 0 \\
* & * & * & * & * & * & * & 0 \\
* & * & * & * & * & * & * & * \\
\end{bmatrix}
 \\
\Theta_{\infty} = (B_0-B_1-B_2-B_3-B_4)^{-1} &=
\begin{bmatrix}
* & * & * & * & * & * & * & * \\
* & * & * & * & * & * & * & * \\
* & * & * & * & 0 & * & * & * \\
* & * & * & * & * & * & * & * \\
* & * & * & * & * & * & * & * \\
* & * & * & * & * & * & * & * \\
* & * & * & * & * & * & * & * \\
* & * & * & * & * & * & * & * \\
\end{bmatrix}
\end{align*}
$$

Where the structural form model is $QB_0y_t=Qb_0+QB_1y_{t-1}+QB_2y_{t-2}+QB_3y_{t-3}+QB_3y_{t-4}+Qu_t,  \quad u_t|Y_{t-1} \sim iid(0_8, I_8)$


## Normalization and Q matrix
To apply a long-run restriction, I need a rotation matrix for it. Obtaining the rotation matrix under the algorithm in Rubio-Ramírez, Waggoner & Zha (2010) requires a contemporaneous relationship matrix $B_0$ such that the number of restrictions in each column is weakly decreasing from the left to the right. Thus, I rearrange the contemporaneous relationship matrix $B_0$ as follows:

$$
\begin{align*}
\Theta_0 = B = B_0^{-1} &=
\begin{bmatrix}
0 & 0 & 0 & 0 & 0 & 0 & 0 & * \\
0 & 0 & 0 & 0 & 0 & 0 & * & * \\
0 & 0 & 0 & * & 0 & * & * & * \\
0 & 0 & 0 & 0 & * & * & * & * \\
0 & 0 & 0 & * & * & * & * & * \\
0 & 0 & * & * & * & * & * & * \\
0 & * & * & * & * & * & * & * \\
* & * & * & * & * & * & * & * \\
\end{bmatrix}
 \\
\Theta_{\infty} = (B_0-B_1-B_2-B_3-B_4)^{-1} &=
\begin{bmatrix}
* & * & * & * & * & * & * & * \\
* & * & * & * & * & * & * & * \\
* & * & * & 0 & * & * & * & * \\
* & * & * & * & * & * & * & * \\
* & * & * & * & * & * & * & * \\
* & * & * & * & * & * & * & * \\
* & * & * & * & * & * & * & * \\
* & * & * & * & * & * & * & * \\
\end{bmatrix}
\end{align*}
$$
 

```{r results for case 2: long-run restriction}
#| echo: false
#| message: false
#| warning: false
#| results: hide

# This code is from ECOM90007 L13 codes provided by Tomasz Woźniak.


# obtain Bplus.posterior.tilde and Binf = B0-B1-B2-B3-B4
############################################################
B0.posterior.tilde    = array(NA,c(N,N,S))
Bplus.posterior.tilde = array(NA,c(N,N*p+1,S))
Binf.tilde            = array(NA,c(N,N,S))
IR.0.tilde            = array(NA,c(N,N,S))
IR.infinity.tilde     = array(NA,c(N,N,S))
IR.0                  = array(NA,c(N,N,S))
IR.infinity           = array(NA,c(N,N,S))
Q.s                   = array(NA,c(N,N,S))

# for (s in 1:S){
#   B0.posterior.tilde[,,s]     = solve(B.posterior[,,s])
#   Bplus.posterior.tilde[,,s]  = B0.posterior.tilde[,,s]%*%t(A.posterior[,,s])
#   Binf.tilde[,,s]             =   B0.posterior.tilde[,,s] - Bplus.posterior.tilde[,2:9,s] - Bplus.posterior.tilde[,10:17,s] - Bplus.posterior.tilde[,18:25,s] - Bplus.posterior.tilde[,26:33,s]
# IR.0.tilde[,,s]               = solve(B0.posterior.tilde[,,s])
# IR.infinity.tilde[,,s]        = solve(Binf.tilde[,,s])
# 
#   }

```


A problem encountered when using a rotation matrix is that structural shocks can only be identified up to a sign, necessitating the need for normalization as a solution. To address this issue, I normalize each draw, denoted as $B^{(s)}$, from the posterior distribution using a function described in Waggoner & Zha (2003). This function returns a normalized matrix, $D_{i*}B_0^{(s)}$, for each $s$th draw, where $D_i$ represents an element from a set of all possible 8 by 8 diagonal matrices. These matrices have diagonal elements consisting of all possible combinations of either 1 or -1.

```{r results for case 2: long-run restriction_contd}
#| echo: true
#| message: false

# normalization process

#1. setup: create an empty array
B.posterior.normalized = array(NA,c(N,N,S))

#1-1. create Di whose rows contain every possible combinations of 1 and -1
values <- c(-1, 1)
combinations <- expand.grid(replicate(8, values, simplify = FALSE))
diag.signs = as.matrix(combinations)
B0.hat.inv = solve(B.posterior[,,1])

#2. conduct normalization
for (s in 1:S) {
B0        <- solve(B.posterior[,,s])
Sigma.inv <- solve(Sigma.posterior[,,s])
normalization.wz2003  = function(B0,B0.hat.inv, Sigma.inv, diag.signs){
  # This function normalizes a matrix of contemporaneous effects
  # according to the algorithm by Waggoner & Zha (2003, JOE)
  # B0        - an NxN matrix, to be normalized
  # B0.hat    - an NxN matrix, a normalized matrix

  NNN               = nrow(B0)
  K                 = 2^NNN
  distance          = rep(NA,K)
  for (k in 1:K){
    B0.tmp.inv      = solve(diag(diag.signs[k,]) %*% B0)
    distance[k]     = sum(
      unlist(
        lapply(1:NNN,
               function(n){
                 t(B0.tmp.inv - B0.hat.inv)[n,] %*%Sigma.inv %*% t(B0.tmp.inv - B0.hat.inv)[n,]
               }
        )))
  }
  B0.out            <- diag(diag.signs[which.min(distance),]) %*% B0
  
  return(B0.out)
B.posterior.normalized[,,s] <- solve(B0.out)
  }
}
```


I proceed to formulate Q matrix by the algorithm1 proposed by Rubio-Ramírez, Waggoner & Zha (2010) as follows:
```{r results for case 2: long-run restriction_contd2}
#| echo: true
#| message: false


# Initial setup
for (s in 1:S){
IR.0.tilde[,,s]               = B.posterior[,,s]
IR.infinity.tilde[,,s]        = solve(diag(N)-t(A.posterior[2:9,,s])-t(A.posterior[10:17,,s])-t(A.posterior[18:25,,s])-t(A.posterior[26:33,,s]))%*%B.posterior[,,s]
  }

# Reverse the order of column so that the ranks of restrictions are in descending order.
for (s in 1:S){
IR.0.tilde[,,s]               = IR.0.tilde[,ncol(IR.0.tilde[,,s]):1,s]
IR.infinity.tilde[,,s]        = IR.infinity.tilde[,ncol(IR.infinity.tilde[,,s]):1,s]
  }


# Orthogonal complement matrix
############################################################
orthogonal.complement.matrix.TW = function(x){
  # x is a mxn matrix and m>n
  # the function returns a mx(m-n) matrix, out, that is an orthogonal complement of x, i.e.:
  # t(x)%*%out = 0 and det(cbind(x,out))!=0
  NN     = dim(x)
  tmp   = qr.Q(qr(x, tol = 1e-10),complete=TRUE)
  out   = as.matrix(tmp[,(NN[2]+1):NN[1]])
  return(out)
}


# Use Algorithm 1 to obtain Q
############################################################
R8 = matrix(0,1,16)
R7 = cbind(diag(1), matrix(0, 1, 15))
R6 = cbind(diag(2),matrix(0, 2,14))
R5 = cbind(diag(3),matrix(0, 3,13))

R4 = matrix(0, 4,16)
R4[1,1]  = 1
R4[2,2]  = 1
R4[3,4]  = 1
R4[4,11] = 1

R3 = cbind(diag(5),matrix(0, 5,11))
R2 = cbind(diag(6),matrix(0, 6,10))
R1 = cbind(diag(7),matrix(0, 7,9))


for (s in 1:S){
fAA             = rbind(IR.0.tilde[,,s],IR.infinity.tilde[,,s])
p1.s            = orthogonal.complement.matrix.TW(t(R1 %*% fAA))
p2.s            = orthogonal.complement.matrix.TW(cbind(t(R2 %*% fAA),p1.s))
p3.s            = orthogonal.complement.matrix.TW(cbind(t(R3 %*% fAA),p1.s,p2.s))
p4.s            = orthogonal.complement.matrix.TW(cbind(t(R4 %*% fAA),p1.s,p2.s,p3.s))
p5.s            = orthogonal.complement.matrix.TW(cbind(t(R5 %*% fAA),p1.s,p2.s,p3.s,p4.s))
p6.s            = orthogonal.complement.matrix.TW(cbind(t(R6 %*% fAA),p1.s,p2.s,p3.s,p4.s,p5.s))
p7.s            = orthogonal.complement.matrix.TW(cbind(t(R7 %*% fAA),p1.s,p2.s,p3.s,p4.s,p5.s,p6.s))
p8.s            = orthogonal.complement.matrix.TW(cbind(p1.s,p2.s,p3.s,p4.s,p5.s,p6.s,p7.s))

Q.s[,,s]         = t(cbind(p1.s,p2.s,p3.s,p4.s,p5.s,p6.s,p7.s,p8.s))
IR.0[,,s]        = IR.0.tilde[,,s]%*%solve(Q.s[,,s])
IR.infinity[,,s] = IR.infinity.tilde[,,s]%*%solve(Q.s[,,s])    
}
```

## Empirical Investigation for model with long-run restriction (case 2)

Unlike the baseline model, the relationship between Australian real GDP and cash rate in the long-run is restricted such that there cash rate has no effect on Australian real GDP. Though this alternative restriction, I expect that the result would not be quite different from the result of the baseline model. This is because if I look at the IRF of Australian real GDP to cash rate, the effect is not different from zero statistically.

```{r results for case 2: long-run restriction_IRF, FEVD}
#| echo: false
#| message: false
#| warning: false
#| results: hide


# Impulse response functions
# Forecast Error Variance Decomposition
############################################################
IRF.posterior     = array(NA,c(N,N,h+1,S))
IRF.inf.posterior = array(NA,c(N,N,S))
FEVD.posterior    = array(NA,c(N,N,h+1,S))
J                 = cbind(diag(N),matrix(0,N,N*(p-1)))
for (s in 1:S){
  A.bold          = rbind(Q.s[,,s]%*%t(A.posterior[2:(1+N*p),,s]),cbind(diag(N*(p-1)),matrix(0,N*(p-1),N)))
  IRF.inf.posterior[,,s]          = IR.infinity[,,s]
  A.bold.power    = A.bold
  for (i in 1:(h+1)){
    if (i==1){
      IRF.posterior[,,i,s]        = IR.0[,,s]
    } else {
      IRF.posterior[,,i,s]        = J %*% A.bold.power %*% t(J) %*% IRF.posterior[,,i-1,s]
#      A.bold.power                = A.bold.power %*% A.bold
    }
    for (n in 1:N){
      for (nn in 1:N){
        FEVD.posterior[n,nn,i,s]  = sum(IRF.posterior[n,nn,1:i,s]^2)
      }
    }
    FEVD.posterior[,,i,s]         = diag(1/apply(FEVD.posterior[,,i,s],1,sum))%*%FEVD.posterior[,,i,s]
  }
}
FEVD.posterior    = 100*FEVD.posterior

t1          = proc.time()
(t1-t0)[3]/60 # Time of computations in minutes

# save(IRF.posterior,IRF.inf.posterior, FEVD.posterior, file="irf-fevd-k002.RData")
save(IRF.posterior,IRF.inf.posterior, FEVD.posterior, file="irf-fevd-k1.RData3")


# Plots of responses to domestic monetary policy shock
############################################################
load("irf-fevd-k1.RData3")
IRFs.k1           = apply(IRF.posterior[1:6,4,,],1:2,mean)
IRFs.inf.k1       = apply(IRF.inf.posterior[1:6,4,],1,mean)
#rownames(IRFs.k1) = colnames(Y)[8:3]
rownames(IRFs.k1) = c('AUD/USD ER','Bank Credit','Deposits','Cash Rate','CPI','GDP')

IRFs.k1.hdi    = apply(IRF.posterior[1:6,4,,],1:2,hdi, credMass=0.68)
hh             = 1:11



```




###### Figure 7. IRF to cash rate shock for $\kappa_1$ = 1 plots {style="text-align: center;"}

```{r irf-au-mps plots3, echo = FALSE}

# irf-au-mps plots

# par(mfrow=c(3,2), mar=c(4,4.5,2,2),cex.axis=1.5, cex.lab=1.5)
# for (n in 1:6){
#   ylims     = range(IRFs.k1[n,hh],IRFs.k1.hdi[,n,hh])
#   plot(hh,IRFs.k1[n,hh], type="l", ylim=ylims, axes=FALSE, xlab="", ylab=rownames(IRFs.k1)[n])
#   if (n==5 | n==6){
#     axis(1,c(1,2,6,11),c("","1 quarter","5 quarter","10 quarter"))
#   } else {
#     axis(1,c(1,2,6,11),c("","","",""))
#   }
#   axis(2,c(ylims[1],0,ylims[2]),round(c(ylims[1],0,ylims[2]),3))
#   polygon(c(hh,(h+1):1), c(IRFs.k1.hdi[1,n,hh],IRFs.k1.hdi[2,n,(h+1):1]), col=mcxs1.shade1,border=mcxs1.shade1)
#   abline(h=0)
#   lines(hh, IRFs.k1[n,hh],lwd=2,col=mcxs1)
#   
# }


plot_irfs(IRFs.k1, IRFs.k1.hdi, hh, c(1,2,6,11), c('','1 quarter','5 quarter','10 quarter'))


```


###### Figure 8. FEVD of banks' credit plots {style="text-align: center;"}


```{r fevd-credit plots3, echo = FALSE}
# Plots of FEVD of Australian banks credit
############################################################
load("irf-fevd-k1.RData")
hh            = 1:(h+1)
fevd.au.credit= apply(FEVD.posterior[2,,,],1:2,mean)
fevd.au.credit= rbind(rep(0,h+1),apply(fevd.au.credit,2,cumsum))

colors = c("deepskyblue1","deepskyblue2","maroon1","maroon","maroon2","magenta","maroon3","maroon4")


par(mar=rep(4,4),cex.axis=1, cex.lab=0.8)
plot(hh,fevd.au.credit[1,], type="n", ylim=c(0,100), axes=FALSE, xlab="", ylab="")
axis(1,hh,c("","1 quarter","","","","5 quarter","","","","","10 quarter"))
axis(2,c(0,50,100),c("","FEVD[au.credit]",""))
for (n in 1:N){
  polygon(c(hh,(h+1):1), c(fevd.au.credit[n,hh],fevd.au.credit[n+1,(h+1):1]), col=colors[n],border=colors[n])
}
axis(4, (0.5*(fevd.au.credit[1:8,2]+fevd.au.credit[2:9,2]))[c(2,4)], c("crd", "mps"))

```



# Identiying assumptions: case 3 (7 variables without deposit)
```{r, warning=FALSE, message=FALSE}
#| echo: false
#| message: false
#| warning: false
#| results: hide
# dm_us_ex_rate, dm_cashrate are original, others are log transformed.
y2          = cbind(log_merged_data[,1],
                    log_merged_data[,2],
                    log_merged_data[,3],
                    log_merged_data[,4],
                        merged_data[,8],
                    log_merged_data[,5],
                        merged_data[,7]
                    )

colnames(y2) <- c("commodity price", "usgdp", "GDP", "CPI", "Cash rate", "Bank credit", "AUD/USD ER")

```

In case 3, I shut down the deposit channel to see how banks' credit respond upon cash rate shock. Following equation summarizes the contemporaneous relationships among the variables in this case:

$$
B_0y_t =
\begin{bmatrix}
a_{11} & 0 & 0 & 0 & 0 & 0 & 0 \\
a_{21} & a_{22} & 0 & 0 & 0 & 0 & 0 \\
a_{31} & a_{32} & a_{33} & 0 & 0 & 0 & 0 \\
a_{41} & a_{42} & a_{43} & a_{44} & 0 & 0 & 0 \\
a_{51} & a_{52} & a_{53} & a_{54} & a_{55} & 0 & 0 \\
a_{61} & a_{62} & a_{63} & a_{64} & a_{65} & a_{66} & 0 \\
a_{71} & a_{72} & a_{73} & a_{74} & a_{75} & a_{76} & a_{77}\\
\end{bmatrix}
\begin{bmatrix}
com_t \\
usgdp_t \\
gdp_t \\
\pi_t \\
i_t \\
credit_t \\
ex_t \\
\end{bmatrix}
$$





```{r results for case 3}
#| echo: false
#| message: false
#| warning: false
#| results: hide

# This code is from ECOM90007 L12 codes provided by Tomasz Woźniak.

library(mvtnorm)
library(plot3D)
library(HDInterval)
set.seed(123456)


# setup
############################################################
N2      = 7
p       = 4
S       = 50000
h       = 8

# create Y and X
############################################################
y2      = ts(y2)
Y       = ts(y2[5:118,], start=c(1991,1), frequency=4)
X       = matrix(1,nrow(Y),1)
for (i in 1:p){
  X     = cbind(X,y2[5:118-i,])
}


t0          = proc.time() # read processor time

# MLE
############################################################
A.hat       = solve(t(X)%*%X)%*%t(X)%*%Y
Sigma.hat   = t(Y-X%*%A.hat)%*%(Y-X%*%A.hat)/nrow(Y)
# round(A.hat,3)
# round(Sigma.hat,3)
# round(cov2cor(Sigma.hat),3)

# prior distribution
############################################################
kappa.1        = 1^2
kappa.2        = 100
kappa.3        = 1
A.prior        = matrix(0,nrow(A.hat),ncol(A.hat))
A.prior[2:8,]  = kappa.3*diag(N2)
V.prior        = diag(c(kappa.2,kappa.1*((1:p)^(-2))%x%rep(1,N2)))
S.prior        = diag(diag(Sigma.hat))
nu.prior       = N2+1

# normal-inverse Wishard posterior parameters
############################################################
V.bar.inv   = t(X)%*%X + diag(1/diag(V.prior))
V.bar       = solve(V.bar.inv)
A.bar       = V.bar%*%(t(X)%*%Y + diag(1/diag(V.prior))%*%A.prior)
nu.bar      = nrow(Y) + nu.prior
S.bar       = S.prior + t(Y)%*%Y + t(A.prior)%*%diag(1/diag(V.prior))%*%A.prior - t(A.bar)%*%V.bar.inv%*%A.bar
S.bar.inv   = solve(S.bar)

# posterior draws 
############################################################
Sigma.posterior   = rWishart(S, df=nu.bar, Sigma=S.bar.inv)
Sigma.posterior   = apply(Sigma.posterior,3,solve)
Sigma.posterior   = array(Sigma.posterior,c(N2,N2,S))
A.posterior       = array(rnorm(prod(c(dim(A.bar),S))),c(dim(A.bar),S))
B.posterior       = array(NA,c(N2,N2,S))
L                 = t(chol(V.bar))
for (s in 1:S){
  cholSigma.s     = chol(Sigma.posterior[,,s])
  B.posterior[,,s]= t(cholSigma.s)
  A.posterior[,,s]= A.bar + L%*%A.posterior[,,s]%*%cholSigma.s
}
# round(apply(A.posterior,1:2,mean),4)
# round(apply(B.posterior,1:2,mean),4)


# Impulse response functions
# Forecast Error Variance Decomposition
############################################################
IRF.posterior     = array(NA,c(N2,N2,h+1,S))
IRF.inf.posterior = array(NA,c(N2,N2,S))
FEVD.posterior    = array(NA,c(N2,N2,h+1,S))
J                 = cbind(diag(N2),matrix(0,N2,N2*(p-1)))
for (s in 1:S){
  A.bold          = rbind(t(A.posterior[2:(1+N2*p),,s]),cbind(diag(N2*(p-1)),matrix(0,N2*(p-1),N2)))
  IRF.inf.posterior[,,s]          = J %*% solve(diag(N2*p)-A.bold) %*% t(J) %*% B.posterior[,,s]
  A.bold.power    = A.bold
  for (i in 1:(h+1)){
    if (i==1){
      IRF.posterior[,,i,s]        = B.posterior[,,s]
    } else {
      IRF.posterior[,,i,s]        = J %*% A.bold.power %*% t(J) %*% IRF.posterior[,,i-1,s]
      A.bold.power                = A.bold.power %*% A.bold
    }
    for (n in 1:N2){
      for (nn in 1:N2){
        FEVD.posterior[n,nn,i,s]  = sum(IRF.posterior[n,nn,1:i,s]^2)
      }
    }
    FEVD.posterior[,,i,s]         = diag(1/apply(FEVD.posterior[,,i,s],1,sum))%*%FEVD.posterior[,,i,s]
  }
}
FEVD.posterior    = 100*FEVD.posterior

t1          = proc.time()
(t1-t0)[3]/60 # Time of computations in minutes

# save(IRF.posterior,IRF.inf.posterior, FEVD.posterior, file="irf-fevd-k002.RData")
save(IRF.posterior,IRF.inf.posterior, FEVD.posterior, file="irf-fevd-k1.RData2")


# Plots of responses to domestic monetary policy shock
############################################################
load("irf-fevd-k1.RData2")
IRFs.k1           = apply(IRF.posterior[3:7,5,,],1:2,mean)
IRFs.inf.k1       = apply(IRF.inf.posterior[3:7,5,],1,mean)
rownames(IRFs.k1) = colnames(Y)[3:7]

IRFs.k1.hdi    = apply(IRF.posterior[3:7,5,,],1:2,hdi, credMass=0.68)
hh             = 1:9
```


## Empirical Investigation for model without deposit (case 3)
As we see the figure of response function of banks credit to cash rate shock, banks credit decreases less upon a positive cash rate shock in the model without banks' deposit. Another interesting observation is that GDP also decreases less under this model than it did in baseline model in which deposit is included. In other words, GDP, a real economy variable, and credit, a financial economy variable are both responding more sensitively to monetary policy shock when deposit is included in the model. 



###### Figure 9. IRF to cash rate shock for $\kappa_1$ = 1 plots {style="text-align: center;"}

```{r irf-au-mps plots2, echo = FALSE}

# irf-au-mps plots

# par(mfrow=c(3,2), mar=c(4,4.5,2,2),cex.axis=1.5, cex.lab=1.5)
# for (n in 1:5){
#   ylims     = range(IRFs.k1[n,hh],IRFs.k1.hdi[,n,hh])
#   plot(hh,IRFs.k1[n,hh], type="l", ylim=ylims, axes=FALSE, xlab="", ylab=rownames(IRFs.k1)[n])
#   if (n==4 | n==5){
#     axis(1,c(1,2,5,9),c("","1 quarter","1 year","2 years"))
#   } else {
#     axis(1,c(1,2,5,9),c("","","",""))
#   }
#   axis(2,c(ylims[1],0,ylims[2]),round(c(ylims[1],0,ylims[2]),3))
#   polygon(c(hh,(h+1):1), c(IRFs.k1.hdi[1,n,hh],IRFs.k1.hdi[2,n,(h+1):1]), col=mcxs1.shade1,border=mcxs1.shade1)
#   abline(h=0)
#   lines(hh, IRFs.k1[n,hh],lwd=2,col=mcxs1)
#   
# }

plot_irfs(IRFs.k1, IRFs.k1.hdi, hh, c(1,2,5,9), c('','1 quarter','1 year','2 years'))

```


###### Figure 10. FEVD of banks' credit plots {style="text-align: center;"}


```{r fevd-credit plots2, echo = FALSE}
# Plots of FEVD of Australian banks credit
############################################################
load("irf-fevd-k1.RData2")
hh            = 1:(h+1)
fevd.au.credit= apply(FEVD.posterior[6,,,],1:2,mean)
fevd.au.credit= rbind(rep(0,h+1),apply(fevd.au.credit,2,cumsum))

colors = c("deepskyblue1","deepskyblue2","maroon1","maroon","maroon2","magenta","maroon3")


par(mar=rep(4,4),cex.axis=1, cex.lab=0.8)
plot(hh,fevd.au.credit[1,], type="n", ylim=c(0,100), axes=FALSE, xlab="", ylab="")
axis(1,hh,c("","1 quarter","","","1 year","","","","2 years"))
axis(2,c(0,50,100),c("","FEVD[au.credit]",""))
for (n in 1:N2){
  polygon(c(hh,(h+1):1), c(fevd.au.credit[n,hh],fevd.au.credit[n+1,(h+1):1]), col=colors[n],border=colors[n])
}
axis(4, (0.5*(fevd.au.credit[1:7,6]+fevd.au.credit[2:8,6]))[c(5,6)], c("mps","crds"))
```

# References {.unnumbered}

